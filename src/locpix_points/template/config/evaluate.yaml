# whether to load the data directly from the gpu
load_data_from_gpu: False

# whether making node or whole graph predictions
label_level: graph # Options: [node, graph]

# number of classes in the dataset
num_classes: 2

# whether to evaluate on the gpu
eval_on_gpu: True

# choice of model
model: locclusternet # Options: see below

# parameters for the network
locclusternet:

  # +++ LocNet parameters +++
  loc_conv_type: pointnet # Options: [pointnet, pointtransformer]
  # Ratio of points to sample from the point cloud
  ratio: 1.0
  # For each point we sample nearest neighbours up to nearest neighbours (k)
  k: 3

  # +++++ PointNet parameters +++++
  local_channels: [[2, 4, 6],[12, 14, 16], [22,24,26]]
  global_channels: [[6, 8, 10],[16, 18, 20], [26,28,30]]
  global_sa_channels: [32, 30, 28, 26]
  final_channels: [26, 24, 22, 8]
  # For each point we sample nearest neighbours up to radius
  radius: 1.0

  # +++++ PointTransformer parameters +++++
  # Number of channels input to first MLP
  in_channels: 0
  # Number of channels out of the final layer
  out_channels: 8
  # Channels for the transformer/transition down blocks
  dim_model: [16, 32, 64]
  pos_nn_layers: 64
  attn_nn_layers: 64
  # Hidden channels for final MLP
  output_mlp_layers: 128

  # ++++++++++++++++++++++++++++++++++++++++

  # +++++ ClusterNet parameters +++++
  # Dropout for each layer during evaluate should be 0.0
  dropout: 0.0 # CAREFUL CHANGING!
  cluster_conv_type: pointnet # Options: [gin, transformer, pointnet, pointtransformer]
  # number of final output channels
  OutputChannels: 2
  # add position coordinates to each cluster
  add_cluster_pos: False

  # --- if cluster_conv_type == gin OR pointnet ------------
  ClusterEncoderChannels: [[10, 12, 16],[18,20,24],[26,28,32], [34,36,40]]
  # ------------------------------------

  # --- if cluster_conv_type == transformer ----
  # Out channels for each layer
  tr_out_channels: [16, 24, 32, 40]
  # Number of multihead attention layers
  tr_heads: 1
  # If False multi-head attentions are averaged rather than being concatenated
  tr_concat: True
  # See https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.TransformerConv.html for difference
  # when beta is True
  tr_beta: False
  # ------------------------------------

  # --- if cluster_conv_type == pointtransformer ------------
  # input channel size for each layer
  pt_tr_in_channels: [8, 16, 24, 32]
  # output channel size for each layer
  pt_tr_out_channels: [16, 24, 32, 40]
  # size of hidden channel for position NN
  pt_tr_pos_nn_layers: 32
  # size of hidden channel for attention NN
  pt_tr_attn_nn_layers: 32
  # dimensions of data: options = [2,3]
  pt_tr_dim: 2
  # -------------------------------------------------

# ----- Other possible models -------

# model: clusternet
# clusternet:
#
#   # Dropout for each layer during evaluate should be 0.0
#   dropout: 0.0 # CAREFUL CHANGING!
#
#   # +++++ ClusterNet parameters +++++
#   cluster_conv_type: pointnet # Options: [gin, transformer, pointnet, pointtransformer]
#   # number of final output channels
#   OutputChannels: 2
#   # add position coordinates to each cluster
#   add_cluster_pos: False
#
#   # --- if cluster_conv_type == gin OR pointnet ------------
#   ClusterEncoderChannels: [[10, 12, 16],[18,20,24],[26,28,32], [34,36,40]]
#   # ------------------------------------
#
#   # --- if cluster_conv_type == transformer ----
#   # Out channels for each layer
#   tr_out_channels: [16, 24, 32, 40]
#   # Number of multihead attention layers
#   tr_heads: 1
#   # If False multi-head attentions are averaged rather than being concatenated
#   tr_concat: True
#   # See https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.TransformerConv.html for difference
#   # when beta is True
#   tr_beta: False
#   # ------------------------------------
#
#   # --- if cluster_conv_type == pointtransformer ------------
#   # input channel size for each layer
#   pt_tr_in_channels: [8, 16, 24, 32]
#   # output channel size for each layer
#   pt_tr_out_channels: [16, 24, 32, 40]
#   # size of hidden channel for position NN
#   pt_tr_pos_nn_layers: 32
#   # size of hidden channel for attention NN
#   pt_tr_attn_nn_layers: 32
#   # dimensions of data: options = [2,3]
#   pt_tr_dim: 2
#   # -------------------------------------------------
#
# model: clustermlp
# clustermlp:
#   # Dropout for each layer during evaluate should be 0.0
#   dropout: 0.0 # CAREFUL CHANGING!
#
#   # Channels for MLP applied to clusters
#   channels: [8, 16, 24, 32, 2]
#
# model: locnetonly_pointnet
# locnetonly_pointnet:
#   # +++++ PointNet parameters +++++
#   local_channels: [[2, 32, 32, 64],[130, 64, 64, 128]]
#   global_channels: [[64, 128, 128],[128, 256, 256]]
#   global_sa_channels: [258, 128, 128, 128]
#   final_channels: [128, 64, 32, 2]
#   # Ratio of points to sample from the point cloud
#   ratio: 1.0
#   # For each point we sample nearest neighbours up to radius and nearest neighbours (k)
#   radius: 1.0
#   k: 4
#
# model: locnetonly_pointtransformer
# locnetonly_pointtransformer:
#   # +++++ PointTransformer parameters +++++
#   # Ratio of points to sample from the point cloud
#   ratio: 1.0
#   # For each point we sample nearest neighbours up to nearest neighbours (k)
#   k: 4
#   # Number of channels input to first MLP
#   in_channels: 0
#   # Number of channels out of the final layer
#   out_channels: 2
#   # Channels for the transformer/transition down blocks
#   dim_model: [16, 32, 64]
#   pos_nn_layers: 64
#   attn_nn_layers: 64
#   # Hidden channels for final MLP
#   output_mlp_layers: 128
