{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from locpix_points.scripts.visualise import visualise_torch_geometric\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import mplcursors\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_umap_embedding(X, min_dist, n_neighbours):\n",
    "    \"\"\"Run UMAP\n",
    "    \n",
    "    Args:\n",
    "        X (array): Array to fit to\n",
    "        min_dist (float): Distance for umap\n",
    "        n_neighbours (int): n-neighbours for umap\"\"\"\n",
    "\n",
    "    reducer = umap.UMAP(\n",
    "            min_dist=min_dist,\n",
    "            n_neighbors=n_neighbours,\n",
    "    )\n",
    "    embedding = reducer.fit_transform(X)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "def visualise_umap_embedding(embedding, df, label_map):\n",
    "    \"\"\"Visualise UMAP results\n",
    "    \n",
    "    Args:\n",
    "        embedding (array): UMAP embedding\n",
    "        df (dataframe): Dataframe with data in\n",
    "        label_map (dict): Map from numbers to concepts\"\"\"\n",
    "\n",
    "    # Plot UMAP - per cluster\n",
    "    plt.close('all')\n",
    "    %matplotlib widget\n",
    "    plt.scatter(\n",
    "        embedding[:, 0],\n",
    "        embedding[:, 1],\n",
    "        c=[sns.color_palette()[x] for x in df.type.map(label_map)],\n",
    "        label=[x for x in df.type.map(label_map)],\n",
    "        s=5,\n",
    "    )\n",
    "    num_classes = len(label_map.keys())\n",
    "    patches = [\n",
    "        mpatches.Patch(color=sns.color_palette()[i], label=list(label_map.keys())[i])\n",
    "        for i in range(num_classes)\n",
    "    ]\n",
    "    cursor = mplcursors.cursor(hover=False)\n",
    "    cursor.connect(\n",
    "        \"add\", lambda sel: sel.annotation.set_text(f\"{df.file_name[sel.index]}\")\n",
    "    )\n",
    "    plt.legend(handles=patches)\n",
    "    plt.gca().set_aspect(\"equal\", \"datalim\")\n",
    "    plt.title(\"UMAP projection of the dataset\", fontsize=24)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pca_embedding(X, n_components):\n",
    "    \"\"\"Run PCA\n",
    "    \n",
    "    Args:\n",
    "        X (array): Array to fit to\n",
    "        n_components (int): n-components for pca\"\"\"\n",
    "\n",
    "    # transform via PCA\n",
    "    reduced_data = PCA(n_components=n_components).fit_transform(X)\n",
    "\n",
    "    return reduced_data\n",
    "\n",
    "def visualise_pca_embedding(pca_embedding, df, label_map):\n",
    "    \"\"\"Visualise PCA embedding\n",
    "    \n",
    "    Args:\n",
    "        pca_embedding (array): PCA embedded data\n",
    "        df (dataframe): Dataframe with data in\n",
    "        label_map (dict): Map from numbers to concepts\"\"\"\n",
    "    \n",
    "    n_classes = len(label_map.keys())\n",
    "\n",
    "    # convert 2d to 3d if required for plotting\n",
    "    if pca_embedding.shape[1] == 2:\n",
    "        z = np.ones(pca_embedding.shape[0])\n",
    "        z = np.expand_dims(z, axis=1)\n",
    "        pca_embedding = np.concatenate([pca_embedding, z], axis=1)\n",
    "\n",
    "    # colour clusters according to class\n",
    "    colors = np.zeros((len(pca_embedding), 3))\n",
    "    for cls in range(n_classes):\n",
    "        idx = np.argwhere(df.type.map(label_map) == cls)\n",
    "        colors[idx] = sns.color_palette()[cls]\n",
    "        class_label = list(label_map.keys())[list(label_map.values()).index(cls)]\n",
    "        print(f\"Class {class_label} is RGB colour: {sns.color_palette()[cls]}\", flush=True)\n",
    "\n",
    "    # plot clusters in o3d\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(pca_embedding)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    # visualise\n",
    "    _ = o3d.visualization.Visualizer()\n",
    "    o3d.visualization.draw_geometries([point_cloud])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_fn(X, df, label_map):\n",
    "    \"\"\"Run KMeans\n",
    "    \n",
    "    Args:\n",
    "        X (array): Array to fit to\n",
    "        df (dataframe): Dataframe with data in\n",
    "        label_map (dict): Map from numbers to concepts\"\"\"\n",
    "\n",
    "    n_clusters = len(label_map.keys())\n",
    "    y_true = df.type.map(label_map).to_numpy()\n",
    "\n",
    "    # with PCA reduction\n",
    "    reduced_data = PCA(n_components=2).fit_transform(X)\n",
    "    kmeans = KMeans(init=\"k-means++\", n_clusters=n_clusters)\n",
    "    kmeans.fit(reduced_data)\n",
    "    y_pred = kmeans.labels_\n",
    "\n",
    "    print(\"--- K means report (with PCA reduction to 2D) ---\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # without PCA reduction\n",
    "    kmeans = KMeans(init=\"k-means++\", n_clusters=n_clusters)\n",
    "    kmeans.fit(X)\n",
    "    y_pred = kmeans.labels_\n",
    "\n",
    "    print(\"--- K means report (NO PCA reduction) ---\")\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_directory = \"..\"\n",
    "# load config\n",
    "with open(os.path.join(project_directory, \"config/featanalyse_manual.yaml\"), \"r\") as ymlfile:\n",
    "    config_manual = yaml.safe_load(ymlfile)\n",
    "with open(os.path.join(project_directory, \"config/featanalyse_nn.yaml\"), \"r\") as ymlfile:\n",
    "    config_nn = yaml.safe_load(ymlfile)\n",
    "label_map = config_manual[\"label_map\"]\n",
    "assert label_map == config_nn[\"label_map\"]\n",
    "manual_features = config_manual[\"features\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = False\n",
    "umap_n_neighbours = 20\n",
    "umap_min_dist = 0.5\n",
    "pca_n_components = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the manual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = os.path.join(project_directory, \"output/train_df_manual.csv\")\n",
    "train_df = pl.read_csv(train_df)\n",
    "train_df_pd = train_df.to_pandas()\n",
    "\n",
    "if final_test:\n",
    "    test_df = os.path.join(project_directory, \"output/test_df_manual.csv\")\n",
    "    test_df = pl.read_csv(test_df)\n",
    "    test_df_pd = test_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare PCA vs Convex hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,4))\n",
    "sns.scatterplot(data=train_df_pd, x = \"length_pca\", y=\"length_convex_hull\",s=5, ax=ax1)\n",
    "sns.scatterplot(data=train_df_pd, x = \"area_pca\", y=\"area_convex_hull\",s=5, ax=ax2)\n",
    "plt.show()\n",
    "\n",
    "if final_test:\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,4))\n",
    "    sns.scatterplot(data=test_df_pd, x = \"length_pca\", y=\"length_convex_hull\",s=5, ax=ax1)\n",
    "    sns.scatterplot(data=test_df_pd, x = \"area_pca\", y=\"area_convex_hull\",s=5, ax=ax2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster features boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of clusters per FOV, cluster type, ...\n",
    "train_cluster_counts = train_df[\"file_name\"].value_counts()\n",
    "print(\"Number of clusters per FOV:\", train_cluster_counts)\n",
    "# number of clusters in each class\n",
    "train_type_counts = train_df[\"type\"].value_counts()\n",
    "print(\"Number of clusters in each class:\", train_type_counts)\n",
    "\n",
    "# per fov features grouped by mean with std\n",
    "train_df_boxplot = train_df[manual_features + [\"type\", \"file_name\"]].to_pandas()\n",
    "\n",
    "fig, axs = plt.subplots(2,4, figsize=(20,8))\n",
    "assert len(manual_features) == 8\n",
    "counter = 0\n",
    "for feat in manual_features:\n",
    "    sns.boxplot(x='type', y=feat, data=train_df_boxplot, color='k', fill=False, flierprops=dict(marker='x', markersize=5), ax=axs[counter//4][counter%4])\n",
    "    counter += 1\n",
    "plt.show()\n",
    "\n",
    "\n",
    "if final_test:\n",
    "    # number of clusters per FOV, cluster type, ...\n",
    "    test_cluster_counts = test_df[\"file_name\"].value_counts()\n",
    "    print(\"Number of clusters per FOV:\", test_cluster_counts)\n",
    "    # number of clusters in each class\n",
    "    test_type_counts = test_df[\"type\"].value_counts()\n",
    "    print(\"Number of clusters in each class:\", test_type_counts)\n",
    "\n",
    "    # per fov features grouped by mean with std\n",
    "    test_df_boxplot = test_df[manual_features + [\"type\", \"file_name\"]].to_pandas()\n",
    "\n",
    "    fig, axs = plt.subplots(2,4, figsize=(20,8))\n",
    "    assert len(manual_features) == 8\n",
    "    counter = 0\n",
    "    for feat in manual_features:\n",
    "        sns.boxplot(x='type', y=feat, data=test_df_boxplot, color='k', fill=False, flierprops=dict(marker='x', markersize=5), ax=axs[counter//4][counter%4])\n",
    "        counter += 1\n",
    "    plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set-up UMAP/PCA/K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features present in the dataframe\n",
    "not_features = [\"clusterID\", \"x_mean\", \"y_mean\", \"type\", \"file_name\"]\n",
    "features = [x for x in train_df.columns if x not in not_features]\n",
    "\n",
    "# now remove features not selected by user\n",
    "removed_features = [f for f in features if f not in manual_features]\n",
    "print(\"Removed features: \", removed_features)\n",
    "features = [f for f in features if f in manual_features]\n",
    "print(\"Features analysed: \", features)\n",
    "\n",
    "# feature vector\n",
    "train_data_feats = train_df_pd[features].values\n",
    "if final_test:\n",
    "    test_data_feats = test_df_pd[features].values\n",
    "\n",
    "num_features = len(train_data_feats[0])\n",
    "print(\"Num features: \", num_features)\n",
    "############ WARNING ##############\n",
    "# Be careful, if analysing neural net features\n",
    "# Is this the number of features you expect\n",
    "# Did this task use manual features as well\n",
    "\n",
    "scaler = StandardScaler().fit(train_data_feats)\n",
    "X_train = scaler.transform(train_data_feats)\n",
    "if final_test:\n",
    "    X_test = scaler.transform(test_data_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_umap_embedding = generate_umap_embedding(X_train, umap_min_dist, umap_n_neighbours)\n",
    "if final_test:\n",
    "    test_umap_embedding = generate_umap_embedding(X_test, umap_min_dist, umap_n_neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_umap_embedding(train_umap_embedding, train_df_pd, label_map)\n",
    "if final_test:\n",
    "    visualise_umap_embedding(test_umap_embedding, test_df_pd, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pca_embedding = generate_pca_embedding(X_train, pca_n_components)\n",
    "if final_test:\n",
    "    test_pca_embedding = generate_pca_embedding(X_test, pca_n_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_pca_embedding(train_pca_embedding, train_df_pd, label_map)\n",
    "if final_test:\n",
    "    visualise_pca_embedding(test_pca_embedding, test_df_pd, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_fn(X_train, train_df_pd, label_map)\n",
    "if final_test:\n",
    "    k_means_fn(X_test, test_df_pd, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the nn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_nn_loc = os.path.join(project_directory, \"output/train_df_nn_loc.csv\")\n",
    "train_df_nn_loc = pd.read_csv(train_df_nn_loc)\n",
    "\n",
    "train_df_nn_cluster = os.path.join(project_directory, \"output/train_df_nn_cluster.csv\")\n",
    "train_df_nn_cluster = pd.read_csv(train_df_nn_cluster)\n",
    "\n",
    "train_df_nn_fov = os.path.join(project_directory, \"output/train_df_nn_fov.csv\")\n",
    "train_df_nn_fov = pd.read_csv(train_df_nn_fov)\n",
    "\n",
    "if final_test:  \n",
    "    test_df_nn_loc = os.path.join(project_directory, \"output/test_df_nn_loc.csv\")\n",
    "    test_df_nn_loc = pd.read_csv(test_df_nn_loc)\n",
    "\n",
    "    test_df_nn_cluster = os.path.join(project_directory, \"output/test_df_nn_cluster.csv\")\n",
    "    test_df_nn_cluster = pd.read_csv(test_df_nn_cluster)\n",
    "\n",
    "    test_df_nn_fov = os.path.join(project_directory, \"output/test_df_nn_fov.csv\")\n",
    "    test_df_nn_fov = pd.read_csv(test_df_nn_fov)\n",
    "\n",
    "else:\n",
    "    test_df_nn_loc = None\n",
    "    test_df_nn_cluster = None\n",
    "    test_df_nn_fov = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set-up UMAP/PCA/K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_features(train_df, test_df):\n",
    "\n",
    "    # get features present in the dataframe\n",
    "    not_features = [\"type\", \"file_name\"]\n",
    "    features = [x for x in train_df.columns.to_list() if x not in not_features]\n",
    "\n",
    "    # feature vector\n",
    "    train_data_feats_nn = train_df[features].values\n",
    "    if final_test:\n",
    "        test_data_feats_nn = test_df[features].values\n",
    "\n",
    "    num_features = len(train_data_feats_nn[0])\n",
    "    print(\"Num features: \", num_features)\n",
    "    ############ WARNING ##############\n",
    "    # Be careful, if analysing neural net features\n",
    "    # Is this the number of features you expect\n",
    "    # Did this task use manual features as well\n",
    "\n",
    "    scaler = StandardScaler().fit(train_data_feats_nn)\n",
    "    X_train_nn = scaler.transform(train_data_feats_nn)\n",
    "    if final_test:\n",
    "        X_test_nn = scaler.transform(test_data_feats_nn)\n",
    "        \n",
    "        return X_train_nn, X_test_nn\n",
    "    else:\n",
    "        return X_train_nn, None\n",
    "\n",
    "X_train_nn_loc, X_test_nn_loc = prep_features(train_df_nn_loc, test_df_nn_loc)\n",
    "X_train_nn_cluster, X_test_nn_cluster = prep_features(train_df_nn_cluster, test_df_nn_cluster)\n",
    "X_train_nn_fov, X_test_nn_fov = prep_features(train_df_nn_fov, test_df_nn_fov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_umap_embedding_nn_loc = generate_umap_embedding(X_train_nn_loc, umap_min_dist, umap_n_neighbours)\n",
    "train_umap_embedding_nn_cluster = generate_umap_embedding(X_train_nn_cluster, umap_min_dist, umap_n_neighbours)\n",
    "train_umap_embedding_nn_fov = generate_umap_embedding(X_train_nn_fov, umap_min_dist, umap_n_neighbours)\n",
    "if final_test:\n",
    "    test_umap_embedding_nn_loc = generate_umap_embedding(X_test_nn_loc, umap_min_dist, umap_n_neighbours)\n",
    "    test_umap_embedding_nn_cluster = generate_umap_embedding(X_test_nn_cluster, umap_min_dist, umap_n_neighbours)\n",
    "    test_umap_embedding_nn_fov = generate_umap_embedding(X_test_nn_fov, umap_min_dist, umap_n_neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------ LOC ENCODER -------\")\n",
    "visualise_umap_embedding(train_umap_embedding_nn_loc, train_df_nn_loc, label_map)\n",
    "if final_test:\n",
    "    visualise_umap_embedding(test_umap_embedding_nn_loc, test_df_nn_loc, label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------ CLUSTER ENCODER -------\")\n",
    "visualise_umap_embedding(train_umap_embedding_nn_cluster, train_df_nn_cluster, label_map)\n",
    "if final_test:\n",
    "    visualise_umap_embedding(test_umap_embedding_nn_cluster, test_df_nn_cluster, label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------ FOV ENCODER -------\")\n",
    "visualise_umap_embedding(train_umap_embedding_nn_fov, train_df_nn_fov, label_map)\n",
    "if final_test:\n",
    "    visualise_umap_embedding(test_umap_embedding_nn_fov, test_df_nn_fov, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pca_embedding_nn_loc = generate_pca_embedding(X_train_nn_loc, pca_n_components)\n",
    "train_pca_embedding_nn_fov = generate_pca_embedding(X_train_nn_fov, pca_n_components)\n",
    "train_pca_embedding_nn_cluster = generate_pca_embedding(X_train_nn_cluster, pca_n_components)\n",
    "if final_test:\n",
    "    test_pca_embedding_nn_loc = generate_pca_embedding(X_test_nn_loc, pca_n_components)\n",
    "    test_pca_embedding_nn_fov = generate_pca_embedding(X_test_nn_fov, pca_n_components)\n",
    "    test_pca_embedding_nn_cluster = generate_pca_embedding(X_test_nn_cluster, pca_n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------ LOC ENCODER -------\")\n",
    "visualise_pca_embedding(train_pca_embedding_nn_loc, train_df_nn_loc, label_map)\n",
    "if final_test:\n",
    "    visualise_pca_embedding(test_pca_embedding_nn_loc, test_df_nn_loc, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------ CLUSTER ENCODER -------\")\n",
    "visualise_pca_embedding(train_pca_embedding_nn_cluster, train_df_nn_cluster, label_map)\n",
    "if final_test:\n",
    "    visualise_pca_embedding(test_pca_embedding_nn_cluster, test_df_nn_cluster, label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------ FOV ENCODER -------\")\n",
    "visualise_pca_embedding(train_pca_embedding_nn_fov, train_df_nn_fov, label_map)\n",
    "if final_test:\n",
    "    visualise_pca_embedding(test_pca_embedding_nn_fov, test_df_nn_fov, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----- LOC ------\")\n",
    "k_means_fn(X_train_nn_loc, train_df_nn_loc, label_map)\n",
    "if final_test:\n",
    "    k_means_fn(X_test_nn_loc, test_df_nn_loc, label_map)\n",
    "\n",
    "print(\"----- CLUSTER ------\")\n",
    "k_means_fn(X_train_nn_cluster, train_df_nn_cluster, label_map)\n",
    "if final_test:\n",
    "    k_means_fn(X_test_nn_cluster, test_df_nn_cluster, label_map)\n",
    "\n",
    "print(\"----- FOV ------\")\n",
    "k_means_fn(X_train_nn_fov, train_df_nn_fov, label_map)\n",
    "if final_test:\n",
    "    k_means_fn(X_test_nn_fov, test_df_nn_fov, label_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SubgraphX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PgEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"wo_3356\"\n",
    "file_folder = \"fold_0\"\n",
    "\n",
    "# visualise it\n",
    "train_file_map_path = os.path.join(project_directory, f\"processed/{file_folder}/train/file_map.csv\")\n",
    "val_file_map_path = os.path.join(project_directory, f\"processed/{file_folder}/val/file_map.csv\")\n",
    "test_file_map_path = os.path.join(project_directory, f\"processed/{file_folder}/test/file_map.csv\")\n",
    "\n",
    "train_file_map = pd.read_csv(train_file_map_path)\n",
    "val_file_map = pd.read_csv(val_file_map_path)\n",
    "test_file_map = pd.read_csv(test_file_map_path)\n",
    "\n",
    "train_out = train_file_map[train_file_map[\"file_name\"] == file_name]\n",
    "val_out = val_file_map[val_file_map[\"file_name\"] == file_name]\n",
    "test_out = test_file_map[test_file_map[\"file_name\"] == file_name]\n",
    "\n",
    "if len(train_out) > 0:\n",
    "    folder = \"train\"\n",
    "    file_name = train_out[\"idx\"].values[0]\n",
    "if len(val_out) > 0:\n",
    "    folder = \"val\"\n",
    "    file_name = val_out[\"idx\"].values[0]\n",
    "if len(test_out) > 0:\n",
    "    folder = \"test\"\n",
    "    file_name = test_out[\"idx\"].values[0]\n",
    "\n",
    "file_loc = os.path.join(project_directory, f\"processed/{file_folder}/{folder}/{file_name}.pt\")\n",
    "visualise_torch_geometric(file_loc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wed\n",
    "0. Check through analysis notebook and commit changes \n",
    "1. Run new model again\n",
    "2. Test feat analysis and analysis note book \n",
    "3. interactive umap - check works for nn features with the good neural net\n",
    "4. Push branch to GitHub\n",
    "\n",
    "Thurs\n",
    "1. Explainability stuff - implement in notebook where appropriate\n",
    "2. Test this explainability stuff on task 1\n",
    "3. Check this notebook and featanalyse are correct\n",
    "\n",
    "Friday\n",
    "1. Copy into correct scripts folder\n",
    "2. Stat tests\n",
    "3. Test on final test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
