{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4ce1a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptTensor,\n",
    "    PairOptTensor,\n",
    "    PairTensor,\n",
    "    SparseTensor,\n",
    "    torch_sparse,\n",
    ")\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops\n",
    "\n",
    "class CustomNet(MessagePassing):\n",
    "    r\"\"\"The PointNet set layer from the `\"PointNet: Deep Learning on Point Sets\n",
    "    for 3D Classification and Segmentation\"\n",
    "    <https://arxiv.org/abs/1612.00593>`_ and `\"PointNet++: Deep Hierarchical\n",
    "    Feature Learning on Point Sets in a Metric Space\"\n",
    "    <https://arxiv.org/abs/1706.02413>`_ papers\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\gamma_{\\mathbf{\\Theta}} \\left( \\max_{j \\in\n",
    "        \\mathcal{N}(i) \\cup \\{ i \\}} h_{\\mathbf{\\Theta}} ( \\mathbf{x}_j,\n",
    "        \\mathbf{p}_j - \\mathbf{p}_i) \\right),\n",
    "\n",
    "    where :math:`\\gamma_{\\mathbf{\\Theta}}` and :math:`h_{\\mathbf{\\Theta}}`\n",
    "    denote neural networks, *i.e.* MLPs, and\n",
    "    :math:`\\mathbf{P} \\in \\mathbb{R}^{N \\times D}` defines the position of\n",
    "    each point.\n",
    "\n",
    "    Args:\n",
    "        local_nn (torch.nn.Module, optional): A neural network\n",
    "            :math:`h_{\\mathbf{\\Theta}}` that maps node features :obj:`x` and\n",
    "            relative spatial coordinates :obj:`pos_j - pos_i` of shape\n",
    "            :obj:`[-1, in_channels + num_dimensions]` to shape\n",
    "            :obj:`[-1, out_channels]`, *e.g.*, defined by\n",
    "            :class:`torch.nn.Sequential`. (default: :obj:`None`)\n",
    "        global_nn (torch.nn.Module, optional): A neural network\n",
    "            :math:`\\gamma_{\\mathbf{\\Theta}}` that maps aggregated node features\n",
    "            of shape :obj:`[-1, out_channels]` to shape :obj:`[-1,\n",
    "            final_out_channels]`, *e.g.*, defined by\n",
    "            :class:`torch.nn.Sequential`. (default: :obj:`None`)\n",
    "        add_self_loops (bool, optional): If set to :obj:`False`, will not add\n",
    "            self-loops to the input graph. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "\n",
    "    Shapes:\n",
    "        - **input:**\n",
    "          node features :math:`(|\\mathcal{V}|, F_{in})` or\n",
    "          :math:`((|\\mathcal{V_s}|, F_{s}), (|\\mathcal{V_t}|, F_{t}))`\n",
    "          if bipartite,\n",
    "          positions :math:`(|\\mathcal{V}|, 3)` or\n",
    "          :math:`((|\\mathcal{V_s}|, 3), (|\\mathcal{V_t}|, 3))` if bipartite,\n",
    "          edge indices :math:`(2, |\\mathcal{E}|)`\n",
    "        - **output:** node features :math:`(|\\mathcal{V}|, F_{out})` or\n",
    "          :math:`(|\\mathcal{V}_t|, F_{out})` if bipartite\n",
    "    \"\"\"\n",
    "    def __init__(self, local_nn: Optional[Callable] = None,\n",
    "                 global_nn: Optional[Callable] = None,\n",
    "                 add_self_loops: bool = True, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'max')\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.local_nn = local_nn\n",
    "        self.global_nn = global_nn\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        reset(self.local_nn)\n",
    "        reset(self.global_nn)\n",
    "\n",
    "    def forward(self, x: Union[OptTensor, PairOptTensor],\n",
    "                pos: Union[Tensor, PairTensor], edge_index: Adj) -> Tensor:\n",
    "\n",
    "        if not isinstance(x, tuple):\n",
    "            x: PairOptTensor = (x, None)\n",
    "\n",
    "        if isinstance(pos, Tensor):\n",
    "            pos: PairTensor = (pos, pos)\n",
    "\n",
    "        if self.add_self_loops:\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                edge_index, _ = remove_self_loops(edge_index)\n",
    "                edge_index, _ = add_self_loops(\n",
    "                    edge_index, num_nodes=min(pos[0].size(0), pos[1].size(0)))\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                edge_index = torch_sparse.set_diag(edge_index)\n",
    "\n",
    "        # propagate_type: (x: PairOptTensor, pos: PairTensor)\n",
    "        out = self.propagate(edge_index, x=x, pos=pos, size=None)\n",
    "\n",
    "        if self.global_nn is not None:\n",
    "            out = self.global_nn(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j: Optional[Tensor], pos_i: Tensor,\n",
    "                pos_j: Tensor) -> Tensor:\n",
    "        print(\"x_j\", x_j)\n",
    "        print(\"pos_j\", pos_j)\n",
    "        print(\"pos_i\", pos_i)\n",
    "        msg = pos_j - pos_i\n",
    "        if x_j is not None:\n",
    "            msg = torch.cat([x_j, msg], dim=1)\n",
    "        print('message', msg)\n",
    "        if self.local_nn is not None:\n",
    "            msg = self.local_nn(msg)\n",
    "        print('output of message', msg)\n",
    "        return msg\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(local_nn={self.local_nn}, '\n",
    "                f'global_nn={self.global_nn})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e3353fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, ratio, r, nn):\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "        self.r = r\n",
    "        self.conv = CustomNet(nn, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        # ------ fps ---------\n",
    "        # this generates indices to sample from data\n",
    "        # first index represents random value from pos\n",
    "        # all subsequent indices represent values furthest from pos\n",
    "        # ratio defines how many points to sample\n",
    "        idx = fps(pos, batch, ratio=self.ratio)\n",
    "        # ------ radius -------\n",
    "        # finds for each element in pos[idx] all points in pos\n",
    "        # within distance self.r\n",
    "        # row is the pos[idx] indices\n",
    "        # e.g. [0,0,1,1,2,2] - first, second, third points\n",
    "        # col is the index of the nearest points to these\n",
    "        # e.g. [1,0,2,1,3,0]\n",
    "        # this all means that\n",
    "        # pos[idx][0] is nearest to pos[1] and pos[0]\n",
    "        # pos[idx][1] is nearest to pos[2] and pos[1]\n",
    "        # pos[idx][2] is nearest to pos[3] and pos[0]\n",
    "        #row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n",
    "        #                  max_num_neighbors=64)\n",
    "        #edge_index = torch.stack([col, row], dim=0)\n",
    "        row, col = radius(pos,\n",
    "                            pos[idx],\n",
    "                            self.r,\n",
    "                            batch,\n",
    "                            batch[idx],\n",
    "                            max_num_neighbors=64)        \n",
    "        # don't really get this as i think ends up just being same as if \n",
    "        # they hadn't split row and col in first place need to check this!\n",
    "        edge_index = torch.stack([col, row], dim=0)\n",
    "\n",
    "        x_dst = None if x is None else x[idx]\n",
    "        \n",
    "        print(\"x\", x)\n",
    "        print(\"x dst\", x_dst)\n",
    "        print(\"pos\", pos)\n",
    "        print(\"pos idx \", pos[idx])\n",
    "        print(\"edge index\", edge_index)\n",
    "        \n",
    "        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
    "        pos, batch = pos[idx], batch[idx]\n",
    "        return x, pos, batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "951254bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MLP, PointNetConv, fps, global_max_pool, radius, knn_interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da820dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa1_module = SAModule(1.0, 2.0, MLP([4, 64, 64, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20885169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15],\n",
      "        [15, 16],\n",
      "        [17, 18]])\n",
      "x dst tensor([[14, 15],\n",
      "        [17, 18],\n",
      "        [15, 16],\n",
      "        [10, 11],\n",
      "        [12, 13]])\n",
      "pos tensor([[ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [10.0000, 20.0000]])\n",
      "pos idx  tensor([[ 0.5000,  0.0000],\n",
      "        [10.0000, 20.0000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000]])\n",
      "edge index tensor([[0, 1, 2, 3, 4, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
      "        [0, 0, 0, 0, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4]])\n",
      "x_j tensor([[10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15],\n",
      "        [15, 16],\n",
      "        [17, 18],\n",
      "        [10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15],\n",
      "        [15, 16],\n",
      "        [10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15],\n",
      "        [15, 16],\n",
      "        [10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15],\n",
      "        [15, 16]])\n",
      "pos_j tensor([[ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [10.0000, 20.0000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 1.0000,  1.5000]])\n",
      "pos_i tensor([[ 0.5000,  0.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [10.0000, 20.0000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000]])\n",
      "message tensor([[10.0000, 11.0000,  0.5000,  0.0000],\n",
      "        [12.0000, 13.0000,  0.5000,  1.0000],\n",
      "        [14.0000, 15.0000,  0.0000,  0.0000],\n",
      "        [15.0000, 16.0000,  0.5000,  1.5000],\n",
      "        [17.0000, 18.0000,  0.0000,  0.0000],\n",
      "        [10.0000, 11.0000,  0.0000, -1.5000],\n",
      "        [12.0000, 13.0000,  0.0000, -0.5000],\n",
      "        [14.0000, 15.0000, -0.5000, -1.5000],\n",
      "        [15.0000, 16.0000,  0.0000,  0.0000],\n",
      "        [10.0000, 11.0000,  0.0000,  0.0000],\n",
      "        [12.0000, 13.0000,  0.0000,  1.0000],\n",
      "        [14.0000, 15.0000, -0.5000,  0.0000],\n",
      "        [15.0000, 16.0000,  0.0000,  1.5000],\n",
      "        [10.0000, 11.0000,  0.0000, -1.0000],\n",
      "        [12.0000, 13.0000,  0.0000,  0.0000],\n",
      "        [14.0000, 15.0000, -0.5000, -1.0000],\n",
      "        [15.0000, 16.0000,  0.0000,  0.5000]])\n",
      "output of message tensor([[-0.1958,  0.6650, -0.3620],\n",
      "        [ 0.0849,  0.3828,  0.1982],\n",
      "        [ 0.4098,  0.1730,  0.2980],\n",
      "        [ 0.2058,  0.0487,  0.5324],\n",
      "        [ 1.1502, -0.2567,  1.1518],\n",
      "        [-0.3607,  0.1453, -0.3494],\n",
      "        [ 0.1359,  0.0020,  0.0788],\n",
      "        [ 0.5230,  0.0042,  0.4092],\n",
      "        [ 0.6526,  0.0499,  0.5316],\n",
      "        [-0.2218,  0.7671, -0.4227],\n",
      "        [ 0.2384,  0.6020,  0.3610],\n",
      "        [ 0.0734,  0.4788,  0.1979],\n",
      "        [ 0.2675,  0.1181,  0.3871],\n",
      "        [-0.5193,  0.3409, -0.6174],\n",
      "        [ 0.1788,  0.1538,  0.1935],\n",
      "        [ 0.2384,  0.0964,  0.2609],\n",
      "        [ 0.3934, -0.2028,  0.2737]], grad_fn=<AddmmBackward0>)\n",
      "output x tensor([[ 0.4098,  0.6650,  0.5324],\n",
      "        [ 1.1502, -0.2567,  1.1518],\n",
      "        [ 0.6526,  0.1453,  0.5316],\n",
      "        [ 0.2675,  0.7671,  0.3871],\n",
      "        [ 0.3934,  0.3409,  0.2737]], grad_fn=<ScatterReduceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[10,11], [12,13], [14,15], [15,16], [17,18]])\n",
    "#x = None\n",
    "pos = torch.tensor([[1,0], [1,1], [.5,0], [1,1.5], [10,20]])\n",
    "batch = torch.tensor([0, 0, 0, 0, 0])\n",
    "x, pos, batch = sa1_module(x, pos, batch)\n",
    "print('output x', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25528017",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_skip = torch.tensor([[10,11], [12,13], [14,15], [15,16], [17,18], [19,20]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bca303c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 5 but got size 6 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_skip\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 5 but got size 6 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "torch.cat([x,x_skip], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2014cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4098,  0.6650,  0.5324],\n",
       "        [ 1.1502, -0.2567,  1.1518],\n",
       "        [ 0.6526,  0.1453,  0.5316],\n",
       "        [ 0.2675,  0.7671,  0.3871],\n",
       "        [ 0.3934,  0.3409,  0.2737]], grad_fn=<ScatterReduceBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b543b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 11],\n",
       "        [12, 13],\n",
       "        [14, 15],\n",
       "        [15, 16],\n",
       "        [17, 18]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7e36e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SAModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, ratio, r, nn):\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "        self.r = r\n",
    "        self.conv = PointNetConv(nn, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        # ------ fps ---------\n",
    "        # this generates indices to sample from data\n",
    "        # first index represents random value from pos\n",
    "        # all subsequent indices represent values furthest from pos\n",
    "        # ratio defines how many points to sample\n",
    "        idx = fps(pos, batch, ratio=self.ratio)\n",
    "        # ------ radius -------\n",
    "        # finds for each element in pos[idx] all points in pos\n",
    "        # within distance self.r\n",
    "        # row is the pos[idx] indices\n",
    "        # e.g. [0,0,1,1,2,2] - first, second, third points\n",
    "        # col is the index of the nearest points to these\n",
    "        # e.g. [1,0,2,1,3,0]\n",
    "        # this all means that\n",
    "        # pos[idx][0] is nearest to pos[1] and pos[0]\n",
    "        # pos[idx][1] is nearest to pos[2] and pos[1]\n",
    "        # pos[idx][2] is nearest to pos[3] and pos[0]\n",
    "\n",
    "        # note they stack the other way round!\n",
    "        row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n",
    "                          max_num_neighbors=64)\n",
    "        print('row,col', row)\n",
    "        print(col)\n",
    "        edge_index = torch.stack([col, row], dim=0)\n",
    "        print('edge', edge_index)\n",
    "\n",
    "        x_dst = None if x is None else x[idx]\n",
    "        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
    "        pos, batch = pos[idx], batch[idx]\n",
    "        return x, pos, batch\n",
    "\n",
    "\n",
    "class GlobalSAModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, nn):\n",
    "        super().__init__()\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        x = self.nn(torch.cat([x, pos], dim=1))\n",
    "        x = global_max_pool(x, batch)\n",
    "        pos = pos.new_zeros((x.size(0), 2))\n",
    "        batch = torch.arange(x.size(0), device=batch.device)\n",
    "        return x, pos, batch\n",
    "\n",
    "\n",
    "class FPModule(torch.nn.Module):\n",
    "    def __init__(self, k, nn):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch, x_skip, pos_skip, batch_skip):\n",
    "        print('pre inter', x.shape)\n",
    "        x = knn_interpolate(x, pos, pos_skip, batch, batch_skip, k=self.k)\n",
    "        print('post inter', x.shape)\n",
    "        if x_skip is not None:\n",
    "            x = torch.cat([x, x_skip], dim=1)\n",
    "        x = self.nn(x)\n",
    "        return x, pos_skip, batch_skip\n",
    "\n",
    "                                                                                                                                                                               \n",
    "class PointNetClassification(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input channels account for both `pos` and node features.\n",
    "        self.sa1_module = SAModule(0.5, 0.2, MLP([3, 64, 64, 128]))\n",
    "        self.sa2_module = SAModule(0.25, 0.4, MLP([128 + 3, 128, 128, 256]))\n",
    "        self.sa3_module = GlobalSAModule(MLP([256 + 3, 256, 512, 1024]))\n",
    "\n",
    "        self.mlp = MLP([1024, 512, 256, 10], dropout=0.5, norm=None)\n",
    "\n",
    "    def forward(self, data):\n",
    "        sa0_out = (data.x, data.pos, data.batch)\n",
    "        sa1_out = self.sa1_module(*sa0_out)\n",
    "        sa2_out = self.sa2_module(*sa1_out)\n",
    "        sa3_out = self.sa3_module(*sa2_out)\n",
    "        x, pos, batch = sa3_out\n",
    "\n",
    "        return self.mlp(x).log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "class PointNetSegmentation(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input channels account for both `pos` and node features.\n",
    "        self.sa1_module = SAModule(1.0, 2.0, MLP([4, 64, 64, 6]))\n",
    "        self.sa2_module = SAModule(0.2, 2.0, MLP([6 + 2, 128, 128, 3]))\n",
    "        self.sa3_module = GlobalSAModule(MLP([3 + 2, 256, 512, 4]))\n",
    "\n",
    "        self.fp3_module = FPModule(1, MLP([4 + 3, 256, 5]))\n",
    "        self.fp2_module = FPModule(3, MLP([5 + 6, 256, 7]))\n",
    "        self.fp1_module = FPModule(3, MLP([7 + 2, 128, 128, 3]))\n",
    "\n",
    "        self.mlp = MLP([3, 128, 128, num_classes], dropout=0.5, norm=None)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(128, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 128)\n",
    "        self.lin3 = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        sa0_out = (data.x, data.pos, data.batch)\n",
    "        sa1_out = self.sa1_module(*sa0_out)\n",
    "        sa2_out = self.sa2_module(*sa1_out)\n",
    "        #print('here', sa2_out)\n",
    "        #print(sa2_out[1].shape)\n",
    "        sa3_out = self.sa3_module(*sa2_out)\n",
    "        \n",
    "        #print(sa3_out[0].shape)\n",
    "        #print(sa2_out[0].shape)\n",
    "        \n",
    "        fp3_out = self.fp3_module(*sa3_out, *sa2_out)\n",
    "        print('--- prob ----')\n",
    "        print(fp3_out[0].shape)\n",
    "        #print(fp3_)\n",
    "        print(sa1_out[0].shape)\n",
    "        fp2_out = self.fp2_module(*fp3_out, *sa1_out)\n",
    "        #print(fp2_out[0].shape)\n",
    "        #print(sa0_out[0].shape)\n",
    "\n",
    "        x, _, _ = self.fp1_module(*fp2_out, *sa0_out)\n",
    "\n",
    "        return self.mlp(x).log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4c92e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row,col tensor([0, 0, 0, 0, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5])\n",
      "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 5])\n",
      "edge tensor([[0, 1, 2, 3, 4, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 5],\n",
      "        [0, 0, 0, 0, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5]])\n",
      "row,col tensor([0, 0, 0, 0, 1])\n",
      "tensor([0, 2, 3, 4, 5])\n",
      "edge tensor([[0, 2, 3, 4, 5],\n",
      "        [0, 0, 0, 0, 1]])\n",
      "pre inter torch.Size([2, 4])\n",
      "post inter torch.Size([2, 4])\n",
      "--- prob ----\n",
      "torch.Size([2, 5])\n",
      "torch.Size([6, 6])\n",
      "pre inter torch.Size([2, 5])\n",
      "post inter torch.Size([6, 5])\n",
      "pre inter torch.Size([6, 7])\n",
      "post inter torch.Size([6, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4448, -1.0244],\n",
       "        [-0.7809, -0.6125],\n",
       "        [-0.7557, -0.6343],\n",
       "        [-0.7154, -0.6714],\n",
       "        [-0.7031, -0.6833],\n",
       "        [-0.6810, -0.7054]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[10,11], [12,13], [14,15], [15,16], [17,18], [14,14]])\n",
    "pos = torch.tensor([[1,0], [1,1], [.5,0], [1,1.5], [10,20], [11,12]])\n",
    "#x = x.unsqueeze(0)\n",
    "#pos = pos.unsqueeze(0)\n",
    "batch = torch.tensor([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "model = PointNetSegmentation(2)\n",
    "data = Data()\n",
    "data.x = x\n",
    "data.pos = pos\n",
    "data.batch = batch\n",
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1739aeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch_geometric.nn.pool.glob.global_max_pool(x: torch.Tensor, batch: Optional[torch.Tensor], size: Optional[int] = None) -> torch.Tensor>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8dce871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 4, 3]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[0,1,2],[4,2,3], [5,4,1]])\n",
    "global_max_pool(x, batch=torch.tensor([0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ed17d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    print(scores)\n",
    "    p_attn = scores.softmax(dim=-1)\n",
    "    print(p_attn)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c09ac1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 47.5000,  58.0000,  23.0000],\n",
      "        [ 76.0000, 183.5000,  77.5000],\n",
      "        [510.0000,  87.5000,  63.5000]], dtype=torch.float64)\n",
      "tensor([[ 2.7536e-05,  9.9997e-01,  6.3049e-16],\n",
      "        [ 2.0575e-47,  1.0000e+00,  9.2211e-47],\n",
      "        [ 1.0000e+00, 3.2403e-184, 1.2232e-194]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "query = torch.tensor([[5,3,4,2], [4,2,44,1], [99,2,3,1]], dtype=torch.float64)\n",
    "key = torch.tensor([[10,11,2, 2], [1,27,7,1], [1,9,3,1]], dtype=torch.float64)\n",
    "value = torch.tensor([[2,2,4, 4], [1,2,1,1], [1,10,3,1]], dtype=torch.float64)\n",
    "a = attention(query, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c419e36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 2.0000, 1.0001, 1.0001],\n",
       "        [1.0000, 2.0000, 1.0000, 1.0000],\n",
       "        [2.0000, 2.0000, 4.0000, 4.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a3cded00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.attention(query, key, value, mask=None, dropout=None)>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "98dbeb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_forward_hooks', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', 'act', 'act_first', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'channel_list', 'children', 'cpu', 'cuda', 'double', 'dropout', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'in_channels', 'ipu', 'lins', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'norms', 'num_layers', 'out_channels', 'parameters', 'plain_last', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'reset_parameters', 'set_extra_state', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(dir(model.sa1_module.conv.local_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c636bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_forward_hooks', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_lazy_load_hook', '_load_from_state_dict', '_load_hook', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', 'add_module', 'apply', 'bfloat16', 'bias', 'bias_initializer', 'buffers', 'call_super_init', 'children', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'in_channels', 'initialize_parameters', 'ipu', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'out_channels', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'reset_parameters', 'set_extra_state', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'weight', 'weight_initializer', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(dir(model.sa1_module.conv.local_nn.lins[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a8e21ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sa1_module.conv.local_nn.lins[0].weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2f57ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e04e89bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1a462b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b983ca1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "333a1f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead6b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
