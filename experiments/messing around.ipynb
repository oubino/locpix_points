{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5089d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptTensor,\n",
    "    PairOptTensor,\n",
    "    PairTensor,\n",
    "    SparseTensor,\n",
    "    torch_sparse,\n",
    ")\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops\n",
    "\n",
    "class CustomNet(MessagePassing):\n",
    "    r\"\"\"The PointNet set layer from the `\"PointNet: Deep Learning on Point Sets\n",
    "    for 3D Classification and Segmentation\"\n",
    "    <https://arxiv.org/abs/1612.00593>`_ and `\"PointNet++: Deep Hierarchical\n",
    "    Feature Learning on Point Sets in a Metric Space\"\n",
    "    <https://arxiv.org/abs/1706.02413>`_ papers\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\gamma_{\\mathbf{\\Theta}} \\left( \\max_{j \\in\n",
    "        \\mathcal{N}(i) \\cup \\{ i \\}} h_{\\mathbf{\\Theta}} ( \\mathbf{x}_j,\n",
    "        \\mathbf{p}_j - \\mathbf{p}_i) \\right),\n",
    "\n",
    "    where :math:`\\gamma_{\\mathbf{\\Theta}}` and :math:`h_{\\mathbf{\\Theta}}`\n",
    "    denote neural networks, *i.e.* MLPs, and\n",
    "    :math:`\\mathbf{P} \\in \\mathbb{R}^{N \\times D}` defines the position of\n",
    "    each point.\n",
    "\n",
    "    Args:\n",
    "        local_nn (torch.nn.Module, optional): A neural network\n",
    "            :math:`h_{\\mathbf{\\Theta}}` that maps node features :obj:`x` and\n",
    "            relative spatial coordinates :obj:`pos_j - pos_i` of shape\n",
    "            :obj:`[-1, in_channels + num_dimensions]` to shape\n",
    "            :obj:`[-1, out_channels]`, *e.g.*, defined by\n",
    "            :class:`torch.nn.Sequential`. (default: :obj:`None`)\n",
    "        global_nn (torch.nn.Module, optional): A neural network\n",
    "            :math:`\\gamma_{\\mathbf{\\Theta}}` that maps aggregated node features\n",
    "            of shape :obj:`[-1, out_channels]` to shape :obj:`[-1,\n",
    "            final_out_channels]`, *e.g.*, defined by\n",
    "            :class:`torch.nn.Sequential`. (default: :obj:`None`)\n",
    "        add_self_loops (bool, optional): If set to :obj:`False`, will not add\n",
    "            self-loops to the input graph. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "\n",
    "    Shapes:\n",
    "        - **input:**\n",
    "          node features :math:`(|\\mathcal{V}|, F_{in})` or\n",
    "          :math:`((|\\mathcal{V_s}|, F_{s}), (|\\mathcal{V_t}|, F_{t}))`\n",
    "          if bipartite,\n",
    "          positions :math:`(|\\mathcal{V}|, 3)` or\n",
    "          :math:`((|\\mathcal{V_s}|, 3), (|\\mathcal{V_t}|, 3))` if bipartite,\n",
    "          edge indices :math:`(2, |\\mathcal{E}|)`\n",
    "        - **output:** node features :math:`(|\\mathcal{V}|, F_{out})` or\n",
    "          :math:`(|\\mathcal{V}_t|, F_{out})` if bipartite\n",
    "    \"\"\"\n",
    "    def __init__(self, local_nn: Optional[Callable] = None,\n",
    "                 global_nn: Optional[Callable] = None,\n",
    "                 add_self_loops: bool = True, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'max')\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.local_nn = local_nn\n",
    "        self.global_nn = global_nn\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        reset(self.local_nn)\n",
    "        reset(self.global_nn)\n",
    "\n",
    "    def forward(self, x: Union[OptTensor, PairOptTensor],\n",
    "                pos: Union[Tensor, PairTensor], edge_index: Adj) -> Tensor:\n",
    "\n",
    "        if not isinstance(x, tuple):\n",
    "            x: PairOptTensor = (x, None)\n",
    "\n",
    "        if isinstance(pos, Tensor):\n",
    "            pos: PairTensor = (pos, pos)\n",
    "\n",
    "        if self.add_self_loops:\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                edge_index, _ = remove_self_loops(edge_index)\n",
    "                edge_index, _ = add_self_loops(\n",
    "                    edge_index, num_nodes=min(pos[0].size(0), pos[1].size(0)))\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                edge_index = torch_sparse.set_diag(edge_index)\n",
    "\n",
    "        # propagate_type: (x: PairOptTensor, pos: PairTensor)\n",
    "        out = self.propagate(edge_index, x=x, pos=pos, size=None)\n",
    "\n",
    "        if self.global_nn is not None:\n",
    "            out = self.global_nn(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j: Optional[Tensor], pos_i: Tensor,\n",
    "                pos_j: Tensor) -> Tensor:\n",
    "        print(\"x_j\", x_j)\n",
    "        print(\"pos_j\", pos_j)\n",
    "        print(\"pos_i\", pos_i)\n",
    "        msg = pos_j - pos_i\n",
    "        if x_j is not None:\n",
    "            msg = torch.cat([x_j, msg], dim=1)\n",
    "        print('message', msg)\n",
    "        if self.local_nn is not None:\n",
    "            msg = self.local_nn(msg)\n",
    "        print('output of message', msg)\n",
    "        return msg\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(local_nn={self.local_nn}, '\n",
    "                f'global_nn={self.global_nn})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f64052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, ratio, r, nn):\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "        self.r = r\n",
    "        self.conv = CustomNet(nn, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        # ------ fps ---------\n",
    "        # this generates indices to sample from data\n",
    "        # first index represents random value from pos\n",
    "        # all subsequent indices represent values furthest from pos\n",
    "        # ratio defines how many points to sample\n",
    "        idx = fps(pos, batch, ratio=self.ratio)\n",
    "        # ------ radius -------\n",
    "        # finds for each element in pos[idx] all points in pos\n",
    "        # within distance self.r\n",
    "        # row is the pos[idx] indices\n",
    "        # e.g. [0,0,1,1,2,2] - first, second, third points\n",
    "        # col is the index of the nearest points to these\n",
    "        # e.g. [1,0,2,1,3,0]\n",
    "        # this all means that\n",
    "        # pos[idx][0] is nearest to pos[1] and pos[0]\n",
    "        # pos[idx][1] is nearest to pos[2] and pos[1]\n",
    "        # pos[idx][2] is nearest to pos[3] and pos[0]\n",
    "        #row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n",
    "        #                  max_num_neighbors=64)\n",
    "        #edge_index = torch.stack([col, row], dim=0)\n",
    "        row, col = radius(pos,\n",
    "                            pos[idx],\n",
    "                            self.r,\n",
    "                            batch,\n",
    "                            batch[idx],\n",
    "                            max_num_neighbors=64)        \n",
    "        # don't really get this as i think ends up just being same as if \n",
    "        # they hadn't split row and col in first place need to check this!\n",
    "        edge_index = torch.stack([col, row], dim=0)\n",
    "\n",
    "        x_dst = None if x is None else x[idx]\n",
    "        \n",
    "        print(\"x\", x)\n",
    "        print(\"x dst\", x_dst)\n",
    "        print(\"pos\", pos)\n",
    "        print(\"pos idx \", pos[idx])\n",
    "        print(\"edge index\", edge_index)\n",
    "        \n",
    "        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
    "        pos, batch = pos[idx], batch[idx]\n",
    "        return x, pos, batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "921b4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MLP, PointNetConv, fps, global_max_pool, radius, knn_interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88c2184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa1_module = SAModule(1.0, 2.0, MLP([4, 64, 64, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff343fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15],\n",
      "        [15, 16],\n",
      "        [17, 18]])\n",
      "x dst tensor([[14, 15],\n",
      "        [17, 18],\n",
      "        [15, 16],\n",
      "        [10, 11],\n",
      "        [12, 13]])\n",
      "pos tensor([[ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [10.0000, 20.0000]])\n",
      "pos idx  tensor([[ 0.5000,  0.0000],\n",
      "        [10.0000, 20.0000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000]])\n",
      "edge index tensor([[0, 1, 2, 3, 4, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
      "        [0, 0, 0, 0, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4]])\n",
      "x_j tensor([[10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15],\n",
      "        [15, 16],\n",
      "        [17, 18],\n",
      "        [10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15],\n",
      "        [15, 16],\n",
      "        [10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15],\n",
      "        [15, 16],\n",
      "        [10, 11],\n",
      "        [12, 13],\n",
      "        [14, 15],\n",
      "        [15, 16]])\n",
      "pos_j tensor([[ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [10.0000, 20.0000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 1.0000,  1.5000]])\n",
      "pos_i tensor([[ 0.5000,  0.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [ 0.5000,  0.0000],\n",
      "        [10.0000, 20.0000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  1.5000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000]])\n",
      "message tensor([[10.0000, 11.0000,  0.5000,  0.0000],\n",
      "        [12.0000, 13.0000,  0.5000,  1.0000],\n",
      "        [14.0000, 15.0000,  0.0000,  0.0000],\n",
      "        [15.0000, 16.0000,  0.5000,  1.5000],\n",
      "        [17.0000, 18.0000,  0.0000,  0.0000],\n",
      "        [10.0000, 11.0000,  0.0000, -1.5000],\n",
      "        [12.0000, 13.0000,  0.0000, -0.5000],\n",
      "        [14.0000, 15.0000, -0.5000, -1.5000],\n",
      "        [15.0000, 16.0000,  0.0000,  0.0000],\n",
      "        [10.0000, 11.0000,  0.0000,  0.0000],\n",
      "        [12.0000, 13.0000,  0.0000,  1.0000],\n",
      "        [14.0000, 15.0000, -0.5000,  0.0000],\n",
      "        [15.0000, 16.0000,  0.0000,  1.5000],\n",
      "        [10.0000, 11.0000,  0.0000, -1.0000],\n",
      "        [12.0000, 13.0000,  0.0000,  0.0000],\n",
      "        [14.0000, 15.0000, -0.5000, -1.0000],\n",
      "        [15.0000, 16.0000,  0.0000,  0.5000]])\n",
      "output of message tensor([[-0.3679,  0.4338,  0.3584],\n",
      "        [-0.4859, -0.3241,  0.1766],\n",
      "        [-0.2414, -0.5962,  0.2676],\n",
      "        [-0.7132, -0.7924,  0.6049],\n",
      "        [ 0.1637, -0.9534,  0.7574],\n",
      "        [-0.0379,  0.2695,  0.4786],\n",
      "        [ 0.2595, -0.1816,  0.0439],\n",
      "        [-0.2009, -0.8247,  0.0459],\n",
      "        [-0.1560, -0.6735,  0.4462],\n",
      "        [-0.2114,  0.3092,  0.3809],\n",
      "        [-0.3498, -0.6989,  0.1411],\n",
      "        [-0.1918, -0.9607,  0.1779],\n",
      "        [-0.7834, -0.9074,  0.9097],\n",
      "        [-0.0439,  0.2978,  0.3544],\n",
      "        [-0.0915, -0.3032,  0.1664],\n",
      "        [-0.1380, -0.5566, -0.0360],\n",
      "        [-0.2466, -0.7575,  0.5108]], grad_fn=<AddmmBackward0>)\n",
      "output x tensor([[-0.2414,  0.4338,  0.6049],\n",
      "        [ 0.1637, -0.9534,  0.7574],\n",
      "        [ 0.2595,  0.2695,  0.4786],\n",
      "        [-0.1918,  0.3092,  0.9097],\n",
      "        [-0.0439,  0.2978,  0.5108]], grad_fn=<ScatterReduceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[10,11], [12,13], [14,15], [15,16], [17,18]])\n",
    "#x = None\n",
    "pos = torch.tensor([[1,0], [1,1], [.5,0], [1,1.5], [10,20]])\n",
    "batch = torch.tensor([0, 0, 0, 0, 0])\n",
    "x, pos, batch = sa1_module(x, pos, batch)\n",
    "print('output x', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "efd77339",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_skip = torch.tensor([[10,11], [12,13], [14,15], [15,16], [17,18], [19,20]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5837b57f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 5 but got size 6 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_skip\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 5 but got size 6 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "torch.cat([x,x_skip], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "397e987d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4098,  0.6650,  0.5324],\n",
       "        [ 1.1502, -0.2567,  1.1518],\n",
       "        [ 0.6526,  0.1453,  0.5316],\n",
       "        [ 0.2675,  0.7671,  0.3871],\n",
       "        [ 0.3934,  0.3409,  0.2737]], grad_fn=<ScatterReduceBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f6562d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 11],\n",
       "        [12, 13],\n",
       "        [14, 15],\n",
       "        [15, 16],\n",
       "        [17, 18]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1d2d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SAModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, ratio, r, nn):\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "        self.r = r\n",
    "        self.conv = PointNetConv(nn, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        # ------ fps ---------\n",
    "        # this generates indices to sample from data\n",
    "        # first index represents random value from pos\n",
    "        # all subsequent indices represent values furthest from pos\n",
    "        # ratio defines how many points to sample\n",
    "        idx = fps(pos, batch, ratio=self.ratio)\n",
    "        # ------ radius -------\n",
    "        # finds for each element in pos[idx] all points in pos\n",
    "        # within distance self.r\n",
    "        # row is the pos[idx] indices\n",
    "        # e.g. [0,0,1,1,2,2] - first, second, third points\n",
    "        # col is the index of the nearest points to these\n",
    "        # e.g. [1,0,2,1,3,0]\n",
    "        # this all means that\n",
    "        # pos[idx][0] is nearest to pos[1] and pos[0]\n",
    "        # pos[idx][1] is nearest to pos[2] and pos[1]\n",
    "        # pos[idx][2] is nearest to pos[3] and pos[0]\n",
    "\n",
    "        # note they stack the other way round!\n",
    "        row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n",
    "                          max_num_neighbors=64)\n",
    "        print('row,col', row)\n",
    "        print(col)\n",
    "        edge_index = torch.stack([col, row], dim=0)\n",
    "        print('edge', edge_index)\n",
    "\n",
    "        x_dst = None if x is None else x[idx]\n",
    "        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
    "        pos, batch = pos[idx], batch[idx]\n",
    "        return x, pos, batch\n",
    "\n",
    "\n",
    "class GlobalSAModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, nn):\n",
    "        super().__init__()\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        x = self.nn(torch.cat([x, pos], dim=1))\n",
    "        x = global_max_pool(x, batch)\n",
    "        pos = pos.new_zeros((x.size(0), 2))\n",
    "        batch = torch.arange(x.size(0), device=batch.device)\n",
    "        return x, pos, batch\n",
    "\n",
    "\n",
    "class FPModule(torch.nn.Module):\n",
    "    def __init__(self, k, nn):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch, x_skip, pos_skip, batch_skip):\n",
    "        print('pre inter', x.shape)\n",
    "        x = knn_interpolate(x, pos, pos_skip, batch, batch_skip, k=self.k)\n",
    "        print('post inter', x.shape)\n",
    "        if x_skip is not None:\n",
    "            x = torch.cat([x, x_skip], dim=1)\n",
    "        x = self.nn(x)\n",
    "        return x, pos_skip, batch_skip\n",
    "\n",
    "                                                                                                                                                                               \n",
    "class PointNetClassification(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input channels account for both `pos` and node features.\n",
    "        self.sa1_module = SAModule(0.5, 0.2, MLP([3, 64, 64, 128]))\n",
    "        self.sa2_module = SAModule(0.25, 0.4, MLP([128 + 3, 128, 128, 256]))\n",
    "        self.sa3_module = GlobalSAModule(MLP([256 + 3, 256, 512, 1024]))\n",
    "\n",
    "        self.mlp = MLP([1024, 512, 256, 10], dropout=0.5, norm=None)\n",
    "\n",
    "    def forward(self, data):\n",
    "        sa0_out = (data.x, data.pos, data.batch)\n",
    "        sa1_out = self.sa1_module(*sa0_out)\n",
    "        sa2_out = self.sa2_module(*sa1_out)\n",
    "        sa3_out = self.sa3_module(*sa2_out)\n",
    "        x, pos, batch = sa3_out\n",
    "\n",
    "        return self.mlp(x).log_softmax(dim=-1)\n",
    "\n",
    "\n",
    "class PointNetSegmentation(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input channels account for both `pos` and node features.\n",
    "        self.sa1_module = SAModule(1.0, 2.0, MLP([2, 64, 64, 6]))\n",
    "        self.sa2_module = SAModule(0.2, 2.0, MLP([6 + 2, 128, 128, 3]))\n",
    "        self.sa3_module = GlobalSAModule(MLP([3 + 2, 256, 512, 4]))\n",
    "\n",
    "        self.fp3_module = FPModule(1, MLP([4 + 3, 256, 5]))\n",
    "        self.fp2_module = FPModule(3, MLP([5 + 6, 256, 7]))\n",
    "        self.fp1_module = FPModule(3, MLP([7, 128, 128, 3]))\n",
    "\n",
    "        self.mlp = MLP([3, 128, 128, num_classes], dropout=0.5, norm=None)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(128, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 128)\n",
    "        self.lin3 = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        sa0_out = (data.x, data.pos, data.batch)\n",
    "        sa1_out = self.sa1_module(*sa0_out)\n",
    "        sa2_out = self.sa2_module(*sa1_out)\n",
    "        #print('here', sa2_out)\n",
    "        #print(sa2_out[1].shape)\n",
    "        sa3_out = self.sa3_module(*sa2_out)\n",
    "        \n",
    "        #print(sa3_out[0].shape)\n",
    "        #print(sa2_out[0].shape)\n",
    "        \n",
    "        fp3_out = self.fp3_module(*sa3_out, *sa2_out)\n",
    "        print('--- prob ----')\n",
    "        print(fp3_out[0].shape)\n",
    "        #print(fp3_)\n",
    "        print(sa1_out[0].shape)\n",
    "        fp2_out = self.fp2_module(*fp3_out, *sa1_out)\n",
    "        #print(fp2_out[0].shape)\n",
    "        #print(sa0_out[0].shape)\n",
    "\n",
    "        x, _, _ = self.fp1_module(*fp2_out, *sa0_out)\n",
    "\n",
    "        return self.mlp(x).log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "524dbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03a3d5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row,col tensor([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5])\n",
      "tensor([0, 1, 3, 2, 4, 5, 0, 1, 3, 0, 1, 3, 2, 4, 5, 2, 4, 5])\n",
      "edge tensor([[0, 1, 3, 2, 4, 5, 0, 1, 3, 0, 1, 3, 2, 4, 5, 2, 4, 5],\n",
      "        [0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5]])\n",
      "row,col tensor([0, 0, 0, 1, 1, 1])\n",
      "tensor([0, 2, 3, 1, 4, 5])\n",
      "edge tensor([[0, 2, 3, 1, 4, 5],\n",
      "        [0, 0, 0, 1, 1, 1]])\n",
      "pre inter torch.Size([1, 4])\n",
      "post inter torch.Size([2, 4])\n",
      "--- prob ----\n",
      "torch.Size([2, 5])\n",
      "torch.Size([6, 6])\n",
      "pre inter torch.Size([2, 5])\n",
      "post inter torch.Size([6, 5])\n",
      "pre inter torch.Size([6, 7])\n",
      "post inter torch.Size([6, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6925, -0.6938],\n",
       "        [-0.7026, -0.6837],\n",
       "        [-0.7023, -0.6841],\n",
       "        [-0.7000, -0.6863],\n",
       "        [-0.6925, -0.6938],\n",
       "        [-0.6385, -0.7510]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = torch.tensor([[10,11], [12,13], [14,15], [15,16], [17,18], [14,14]])\n",
    "pos = torch.tensor([[2,0], [3,1], [-.5,0], [2,1.5], [0,0], [-0.5,1]])\n",
    "y = torch.tensor([1, 1, 0, 1, 0, 0])\n",
    "\n",
    "#x = x.unsqueeze(0)\n",
    "#pos = pos.unsqueeze(0)\n",
    "batch = torch.tensor([0, 0, 0, 0, 0, 0])\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "model = PointNetSegmentation(2)\n",
    "data = Data()\n",
    "#data.x = x\n",
    "data.pos = pos\n",
    "data.y = y\n",
    "data.batch = batch\n",
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c45069",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=2),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',\n",
    "    ),\n",
    ")\n",
    "node_index = 10\n",
    "explanation = explainer(data.x, data.edge_index, index=node_index)\n",
    "print(explanation.edge_mask)\n",
    "print(explanation.node_mask)\n",
    "print(f'Generated explanations in {explanation.available_explanations}')\n",
    "\n",
    "path = 'feature_importance.png'\n",
    "explanation.visualize_feature_importance(path, top_k=10)\n",
    "print(f\"Feature importance plot has been saved to '{path}'\")\n",
    "\n",
    "path = 'subgraph.pdf'\n",
    "explanation.visualize_graph(path)\n",
    "print(f\"Subgraph visualization plot has been saved to '{path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96453a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import unfaithfulness\n",
    "\n",
    "metric = unfaithfulness(explainer, explanation)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.visualize_feature_importance(top_k=10)\n",
    "\n",
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d04a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(pos=[6, 2], y=[6], batch=[6])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.NormalizeScale(), transforms.RandomShear(0.05)])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "56599850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 4, 3]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[0,1,2],[4,2,3], [5,4,1]])\n",
    "global_max_pool(x, batch=torch.tensor([0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "24305cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    print(scores)\n",
    "    p_attn = scores.softmax(dim=-1)\n",
    "    print(p_attn)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8f7b663d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 47.5000,  58.0000,  23.0000],\n",
      "        [ 76.0000, 183.5000,  77.5000],\n",
      "        [510.0000,  87.5000,  63.5000]], dtype=torch.float64)\n",
      "tensor([[ 2.7536e-05,  9.9997e-01,  6.3049e-16],\n",
      "        [ 2.0575e-47,  1.0000e+00,  9.2211e-47],\n",
      "        [ 1.0000e+00, 3.2403e-184, 1.2232e-194]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "query = torch.tensor([[5,3,4,2], [4,2,44,1], [99,2,3,1]], dtype=torch.float64)\n",
    "key = torch.tensor([[10,11,2, 2], [1,27,7,1], [1,9,3,1]], dtype=torch.float64)\n",
    "value = torch.tensor([[2,2,4, 4], [1,2,1,1], [1,10,3,1]], dtype=torch.float64)\n",
    "a = attention(query, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0706d8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 2.0000, 1.0001, 1.0001],\n",
       "        [1.0000, 2.0000, 1.0000, 1.0000],\n",
       "        [2.0000, 2.0000, 4.0000, 4.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e0a39370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.attention(query, key, value, mask=None, dropout=None)>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "df2abed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_forward_hooks', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', 'act', 'act_first', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'channel_list', 'children', 'cpu', 'cuda', 'double', 'dropout', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'in_channels', 'ipu', 'lins', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'norms', 'num_layers', 'out_channels', 'parameters', 'plain_last', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'reset_parameters', 'set_extra_state', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(dir(model.sa1_module.conv.local_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "de290b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_forward_hooks', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_lazy_load_hook', '_load_from_state_dict', '_load_hook', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', 'add_module', 'apply', 'bfloat16', 'bias', 'bias_initializer', 'buffers', 'call_super_init', 'children', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'in_channels', 'initialize_parameters', 'ipu', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'out_channels', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'reset_parameters', 'set_extra_state', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'weight', 'weight_initializer', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(dir(model.sa1_module.conv.local_nn.lins[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7b1576c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sa1_module.conv.local_nn.lins[0].weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "892fe7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9f662a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "974a1819",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "256a28e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "14b1adb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "68c9bab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_forward_hooks', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'children', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'fp1_module', 'fp2_module', 'fp3_module', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'ipu', 'lin1', 'lin2', 'lin3', 'load_state_dict', 'mlp', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'sa1_module', 'sa2_module', 'sa3_module', 'set_extra_state', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(dir(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2494d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.empty((1))\n",
    "a = torch.tensor([1,2,3])\n",
    "a = torch.cat((e,a))\n",
    "b= torch.tensor([4,5,6])\n",
    "c = torch.cat((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d93f1eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.tensor([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a082b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.cat((c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "10ebc91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 2., 3.])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "611e223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Tuple, Union\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptTensor,\n",
    "    PairTensor,\n",
    "    SparseTensor,\n",
    "    torch_sparse,\n",
    ")\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops, softmax\n",
    "\n",
    "\n",
    "class PointTransformerConv(MessagePassing):\n",
    "    r\"\"\"The Point Transformer layer from the `\"Point Transformer\"\n",
    "    <https://arxiv.org/abs/2012.09164>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i =  \\sum_{j \\in\n",
    "        \\mathcal{N}(i) \\cup \\{ i \\}} \\alpha_{i,j} \\left(\\mathbf{W}_3\n",
    "        \\mathbf{x}_j + \\delta_{ij} \\right),\n",
    "\n",
    "    where the attention coefficients :math:`\\alpha_{i,j}` and\n",
    "    positional embedding :math:`\\delta_{ij}` are computed as\n",
    "\n",
    "    .. math::\n",
    "        \\alpha_{i,j}= \\textrm{softmax} \\left( \\gamma_\\mathbf{\\Theta}\n",
    "        (\\mathbf{W}_1 \\mathbf{x}_i - \\mathbf{W}_2 \\mathbf{x}_j +\n",
    "        \\delta_{i,j}) \\right)\n",
    "\n",
    "    and\n",
    "\n",
    "    .. math::\n",
    "        \\delta_{i,j}= h_{\\mathbf{\\Theta}}(\\mathbf{p}_i - \\mathbf{p}_j),\n",
    "\n",
    "    with :math:`\\gamma_\\mathbf{\\Theta}` and :math:`h_\\mathbf{\\Theta}`\n",
    "    denoting neural networks, *i.e.* MLPs, and\n",
    "    :math:`\\mathbf{P} \\in \\mathbb{R}^{N \\times D}` defines the position of\n",
    "    each point.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int or tuple): Size of each input sample, or :obj:`-1` to\n",
    "            derive the size from the first input(s) to the forward method.\n",
    "            A tuple corresponds to the sizes of source and target\n",
    "            dimensionalities.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        pos_nn (torch.nn.Module, optional): A neural network\n",
    "            :math:`h_\\mathbf{\\Theta}` which maps relative spatial coordinates\n",
    "            :obj:`pos_j - pos_i` of shape :obj:`[-1, 3]` to shape\n",
    "            :obj:`[-1, out_channels]`.\n",
    "            Will default to a :class:`torch.nn.Linear` transformation if not\n",
    "            further specified. (default: :obj:`None`)\n",
    "        attn_nn (torch.nn.Module, optional): A neural network\n",
    "            :math:`\\gamma_\\mathbf{\\Theta}` which maps transformed\n",
    "            node features of shape :obj:`[-1, out_channels]`\n",
    "            to shape :obj:`[-1, out_channels]`. (default: :obj:`None`)\n",
    "        add_self_loops (bool, optional) : If set to :obj:`False`, will not add\n",
    "            self-loops to the input graph. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "\n",
    "    Shapes:\n",
    "        - **input:**\n",
    "          node features :math:`(|\\mathcal{V}|, F_{in})` or\n",
    "          :math:`((|\\mathcal{V_s}|, F_{s}), (|\\mathcal{V_t}|, F_{t}))`\n",
    "          if bipartite,\n",
    "          positions :math:`(|\\mathcal{V}|, 3)` or\n",
    "          :math:`((|\\mathcal{V_s}|, 3), (|\\mathcal{V_t}|, 3))` if bipartite,\n",
    "          edge indices :math:`(2, |\\mathcal{E}|)`\n",
    "        - **output:** node features :math:`(|\\mathcal{V}|, F_{out})` or\n",
    "          :math:`(|\\mathcal{V}_t|, F_{out})` if bipartite\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: Union[int, Tuple[int, int]],\n",
    "                 out_channels: int, pos_nn: Optional[Callable] = None,\n",
    "                 attn_nn: Optional[Callable] = None,\n",
    "                 add_self_loops: bool = True, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.pos_nn = pos_nn\n",
    "        if self.pos_nn is None:\n",
    "            self.pos_nn = Linear(3, out_channels)\n",
    "\n",
    "        self.attn_nn = attn_nn\n",
    "        self.lin = Linear(in_channels[0], out_channels, bias=False)\n",
    "        self.lin_src = Linear(in_channels[0], out_channels, bias=False)\n",
    "        self.lin_dst = Linear(in_channels[1], out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        reset(self.pos_nn)\n",
    "        if self.attn_nn is not None:\n",
    "            reset(self.attn_nn)\n",
    "        self.lin.reset_parameters()\n",
    "        self.lin_src.reset_parameters()\n",
    "        self.lin_dst.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[Tensor, PairTensor],\n",
    "                pos: Union[Tensor, PairTensor], edge_index: Adj) -> Tensor:\n",
    "\n",
    "        if isinstance(x, Tensor):\n",
    "            print('x dtype', x.dtype)\n",
    "            alpha = (self.lin_src(x), self.lin_dst(x))\n",
    "            x: PairTensor = (self.lin(x), x)\n",
    "        else:\n",
    "            alpha = (self.lin_src(x[0]), self.lin_dst(x[1]))\n",
    "            x = (self.lin(x[0]), x[1])\n",
    "\n",
    "        if isinstance(pos, Tensor):\n",
    "            pos: PairTensor = (pos, pos)\n",
    "\n",
    "        if self.add_self_loops:\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                edge_index, _ = remove_self_loops(edge_index)\n",
    "                edge_index, _ = add_self_loops(\n",
    "                    edge_index, num_nodes=min(pos[0].size(0), pos[1].size(0)))\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                edge_index = torch_sparse.set_diag(edge_index)\n",
    "        \n",
    "        print('x shape', x)\n",
    "        print('alpha', alpha)\n",
    "        # propagate_type: (x: PairTensor, pos: PairTensor, alpha: PairTensor)\n",
    "        out = self.propagate(edge_index, x=x, pos=pos, alpha=alpha, size=None)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor, pos_i: Tensor, pos_j: Tensor,\n",
    "                alpha_i: Tensor, alpha_j: Tensor, index: Tensor,\n",
    "                ptr: OptTensor, size_i: Optional[int]) -> Tensor:\n",
    "        \n",
    "        print(alpha_i, 'alpha i')\n",
    "        print(alpha_j, 'alpha j')\n",
    "        delta = self.pos_nn(pos_i - pos_j)\n",
    "        alpha = alpha_i - alpha_j + delta\n",
    "        if self.attn_nn is not None:\n",
    "            alpha = self.attn_nn(alpha)\n",
    "        print('alpha', alpha)\n",
    "        print('index', index)\n",
    "        print('ptr', ptr)\n",
    "        print('size i', size_i)\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        print('alpha', alpha)\n",
    "        print('index', index)\n",
    "        print('ptr', ptr)\n",
    "        print('size i', size_i)\n",
    "        a =  alpha * (x_j + delta)\n",
    "        print('xj', x_j)\n",
    "        print('detla', delta)\n",
    "        print('a', a)\n",
    "        return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f144d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MLP, radius, fps\n",
    "from torch_geometric.data import Data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca7c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "out_channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "011c3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[10,11,12], [12,13,14], [14,15,15]], dtype=torch.float32)\n",
    "pos_nn = MLP([3, 64, out_channels], norm=None, plain_last=False)\n",
    "attn_nn = MLP([out_channels, 64, out_channels], norm=None, plain_last=False)\n",
    "\n",
    "pos = torch.tensor([[2,0, 3], [3,1, 0], [-.5,0,2], [1,2,3]])\n",
    "y = torch.tensor([1, 0, 1])\n",
    "batch = torch.tensor([0, 0, 0])\n",
    "\n",
    "#model = PointTransformerConv(in_channels, out_channels,pos_nn,attn_nn)\n",
    "data = Data()\n",
    "data.x = x\n",
    "data.pos = pos\n",
    "data.y = y\n",
    "data.batch = batch\n",
    "#idx = fps(pos, batch, ratio=0.2)\n",
    "#r = 2.0\n",
    "#row, col = radius(\n",
    "#        pos, pos[idx], r, batch, batch[idx], max_num_neighbors=64)\n",
    "#data.edge_index = torch.stack([col, row], dim=0)\n",
    "\n",
    "data.edge_index = torch.tensor([[0,0,1,1,1,2,2],\n",
    "                           [0,1,0,1,2,2,1]])\n",
    "\n",
    "#model(data.x, data.pos, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65080023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import knn\n",
    "\n",
    "x = torch.tensor([[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [-1.0, 0.0]])\n",
    "batch_x = torch.tensor([0, 0, 0, 0])\n",
    "y = torch.tensor([[-1.0, 0.0], [1.0, 0.0]])\n",
    "batch_y = torch.tensor([0, 0])\n",
    "assign_index = knn(x, y, 2, batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "632d5896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 1],\n",
       "        [3, 0, 2, 3]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assign_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0ed29d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [-1.,  1.],\n",
       "        [ 1., -1.],\n",
       "        [-1.,  0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f15cfa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [-1., -1.],\n",
       "        [-1.,  1.],\n",
       "        [-1.,  1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[assign_index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a073f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97eb59a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [ 0.,  0.],\n",
       "        [-1.,  1.],\n",
       "        [-2.,  0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter(x[assign_index[0]], assign_index[1], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bdf36fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pos.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23887840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(config, **kwargs):\n",
    "    print(config)\n",
    "    print(kwargs['apple'])\n",
    "    print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "441d58d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog'}\n",
      "3\n",
      "{'apple': 3}\n"
     ]
    }
   ],
   "source": [
    "foo ({'dog'}, apple=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "299aebd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test sub sampple\n",
    "\n",
    "\"\"\"This module defines custom transforms to apply to the data\"\"\"\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.datapipes import functional_transform\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.nn import (\n",
    "    radius,\n",
    ")\n",
    "\n",
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# had to change base code as basetransform not implemented yet for me \n",
    "@functional_transform('subsample')\n",
    "class subsample(BaseTransform):\n",
    "    r\"\"\"Samples points and features from a point cloud within a circle\n",
    "    (functional name: :obj:`subsample`).\n",
    "\n",
    "    Args:\n",
    "        radius (float): The size of the circle to sample from in nm\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        radius: float,\n",
    "    ):\n",
    "        self.radius = radius\n",
    "\n",
    "    def forward(self, data: Data) -> Data:\n",
    "        \n",
    "        # sample 1 node id from all the nodes in data\n",
    "        idx = np.random.choice(data.num_nodes, 1)\n",
    "        pos = data.pos\n",
    "        x = data.x\n",
    "        batch = data.batch\n",
    "        row, col = radius(\n",
    "            pos, pos[idx], self.radius, batch, batch[idx]\n",
    "        )\n",
    "        data.edge_index, data.edge_attr = subgraph(col, data.edge_index, data.edge_attr)  \n",
    "        return data\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}({self.radius})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a9a9849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx [3]\n",
      "pos idx tensor([[0, 3]])\n",
      "row tensor([0, 0, 0])\n",
      "col tensor([2, 3, 4])\n",
      "data Data(x=[5, 2], pos=[5, 2], y=[5], batch=[5], edge_index=[2, 13])\n",
      "edge index tensor([[2, 2, 3, 3, 3, 4, 4],\n",
      "        [2, 3, 3, 2, 4, 4, 3]])\n",
      "pos tensor([[0, 0],\n",
      "        [0, 1],\n",
      "        [0, 2],\n",
      "        [0, 3],\n",
      "        [0, 4]])\n",
      "x tensor([[0., 1.],\n",
      "        [2., 3.],\n",
      "        [4., 5.],\n",
      "        [6., 7.],\n",
      "        [8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "\n",
    "pos = torch.tensor([[0,0], [0,1], [0,2], [0,3], [0,4]])\n",
    "y = torch.ones(n)\n",
    "batch = torch.zeros(n)\n",
    "x = torch.arange(n*2, dtype=torch.float32)\n",
    "x = x.reshape(-1,2)\n",
    "\n",
    "data = Data()\n",
    "data.x = x\n",
    "data.pos = pos\n",
    "data.y = y\n",
    "data.batch = batch\n",
    "\n",
    "data.edge_index = torch.tensor([[0,0,1,1,1,2,2,2,3,3,3,4,4],\n",
    "                                [0,1,0,1,2,2,1,3,3,2,4,4,3]])\n",
    "\n",
    "\n",
    "#can then remove isolated nodes!!!!!\n",
    "transform = T.Compose([subsample(2.0), T.RemoveIsolatedNodes()])\n",
    "data = transform(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
