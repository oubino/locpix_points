# device to train on (gpu or cpu)
gpu: True

# model parameters
model: pointtransformerseg

pointnetclass:
  ratio : [0.5,0.25]
  radius : [0.2,0.4]
  # 130 = 128 + dim (2) + dim of feature (0)
  # 258 = 256 + dim (2) + dim of feature (0)
  # num classes = 2
  channels : [[3, 64, 64, 128], [130, 128, 128, 256], [258, 256, 512, 1024], [1024, 512, 256, 2]]
  dropout : 0.5
  norm : null

pointnetseg:
  ratio : [0.2,0.25]
  radius : [0.2, 0.4]
  # 2 = dim (2) + dim of feature (0)
  # 130 = 128 + dim (2) + dim of feature (0)
  # 258 = 256 + dim (2) + dim of feature (0)
  sa_channels : [[2, 64, 64, 128], [130, 128, 128, 256], [258, 256, 512, 1024]]
  k : [1,3,3]
  # 1080 = 1024 + 256 
  # 384 = 256 + 128
  # 130 = 128 + dim (2) + dim of feature (0) 
  fp_channels : [[1080, 256, 256], [384, 256, 128], [130, 128, 128, 128]]
  # num classes = 2
  output_channels : [128, 128, 128, 2]
  dropout : 0.5
  norm : null

pointtransformerclass:
  # used in both transition down and for considreing how many neighbours point transformer should consider
  k: 16
  in_channels: 2
  out_channels: 2
  dim_model: [32, 64, 128, 256, 512]
  output_mlp_layers: 64
  # ratio of points to sample when transition down
  ratio: 0.25
  pos_nn_layers: 64
  attn_nn_layers: 64

pointtransformerseg:
  # used in both transition down and for considreing how many neighbours point transformer should consider
  k: 16
  in_channels: 1
  out_channels: 2
  dim_model: [32, 64, 128, 256, 512]
  k_up: 3 # trilinear interpolation
  output_mlp_layers: 64
  # ratio of points to sample when transition down
  ratio: 0.25
  pos_nn_layers: 64
  attn_nn_layers: 64


# optimiser parameters
optimiser: adam
lr: 0.001
weight_decay: 0.0001

# training parameters
epochs: 50
batch_size: 5
num_workers: 1 # generall higher -> faster
loss_fn: nll

# what trying to predict
label_level: node # graph

# train/val transforms
# options: ['normalisescale', 'jitter', 'flip', 'randscale', 'rotate', 'shear'] # null
transforms: 
  #jitter: 15 # number of nm
  x_flip: null
  y_flip: null 
  #randscale: [0.95,1.05]
  z_rotate: null
  #shear: 0.05
  normalisescale: null

# wandb parameters
wandb_project: nieves_expt3
wandb_dataset: nieves